---
date: 2021-04-13 21:18:38
updated: 2021-04-13 21:18:38
title: 多线程中的锁
index_img: /gallery/2021-08-23-20-13-43.png

tags:
  - System

categories:
  - System

---

# 为什么多线程要加锁

- 多个线程运行的时候，**共享**了**同一块资源**，在访问这块资源的时候就称为**临界资源**
- 多线程可以同时运行多个任务但是当多个线程同时访问共享数据时，可能**导致数据不同步**，甚至错误！

## 关于不加锁的后果分析

```c
#include <stdio.h>
#include <pthread.h>

#define THREAD_NUM 10
int count = 0;
void *proc(void *arg)
{
    int i = 0;
    while( i++ < 100000) {
        count++;
        usleep(1);
    }
}

int main()
{
    int i = 0;
    pthread_t id[THREAD_NUM] = {0};

    for (i = 0; i < THREAD_NUM; i++) {
        pthread_create(&id[i], NULL, proc, NULL);
    }

    while (1) {
        printf("total %d\n", count);
        sleep(1);
    }
    return 0;
}

————————————————
版权声明：本文为CSDN博主「guojunfengcode」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/guojunfenglinux/article/details/108131025
```

- count++翻译成指令，反汇编看看，其实是有三个指令，读 加 写。

```vim
[guojunfeng@guojunfeng mutex]$ objdump -S -d mutex > count
//找到count++的位置
400642:   8b 05 00 0a 20 00       mov    0x200a00(%rip),%eax        # 601048 <__TMC_END__>
400648:   83 c0 01                add    $0x1,%eax
40064b:   89 05 f7 09 20 00       mov    %eax,0x2009f7(%rip)
```

- 所有是分为三步,先读取变量,然后添加 1,然后在把 edx 的数值存到 count 中

- 本来理想状态是以下这样交互达到正确的++

![error_loading](/gallery/2021-04-13-21-32-18.png)

- 竞争资源比较大的时候，会变成以下状态

![error_loading](/gallery/2021-04-13-21-32-53.png)

- 如果上面的 比如说这个时候 count 的数值已经是 100
- 然后这个时候 100 被读取到 CPU eax 寄存器里面
- 但是这个时候,线程中断,然后这时候 eax 被保存到线程栈里面(上下文),然后接下来线程 2 来使用 CPU
- 然后这个时候还是从 `0x200a00(%rip)` 这里取值,但是这个数值时候还没有改变,然后还是 100 被存到 eax 中
- 然后接下来的两步就是加一,然后计算结果 101 ,放到内存 1 里面
- 然后接下来线程一恢复运行线程 一的东西,因为之前保存过 CPU 的状态(eax),然后接下来对 eax(100)加一就还是 101
- 然后就把线程一的结果 101 放到了内存中,最后的结果就是 101

# 总结

- 综上所示就是说明,因为有着线程切换的中断的原因
- 然后中断会保持上下文,然后多线程中,对临界资源的访问是需要保证上下文同步的,所以加锁的目的就是为了保证对上下文资源的同步

## 多线程中各种锁的种类

- 锁机制的作用：有些业务逻辑在执行过程中要求对数据**进行排他性**的访问，于是需要通过一些机制保证在此过程中数据被锁住**不会被外界修改**，这就是所谓的锁机制

---

# **互斥锁**

- 对共享资源的访问必须是顺序的
- 当多个线程对共享资源访问的时候，**只能有一个线程**可以获得该共享资源的**锁**
- 当线程 A 尝试获取线程 B 的锁时，线程 A 必须**等待或者阻塞**
- 直到线程 B 释放该锁为止，否则线程 A 将**一直等待下去**
- 锁实际上是一种**互斥机制**

# **饥饿**

- 线程 T1 占用了资源 R，线程 T2 又请求封锁 R
  - 于是 T2 等待
- T3 也请求资源 R
  - 当 T1 释放了 R 上的封锁后
- 系统首先批准了 T3 的请求，T2 仍然等待
- 然后 T4 又请求资源 R，当 T3 释放了 R 上的封锁之后，系统又批准了 T4 的请求
- **T2 可能永远等待**
- 锁里的**不公平锁机制**
- 不公平锁能够**提高吞吐量**但不可避免的会**造成某些线程的饥饿**

```vim
对饥饿的描述

就好比食堂打饭，刷卡的优先打饭，
付现金的要等刷卡的打完了才能打
可是拿着现金的很早就在那儿准备好了，
可以刷卡的那条队伍却一直来了一个又一个，
来个没完，拿现金的只好**饿死**。


```

# **死锁**

- 在线程间共享多个资源的时候
- 如果线程一占有资源一
- 线程二占有资源二
- 但是线程一需要线程二现在占有的资源二
- 同时,线程二又需要线程一占有的资源一
- 这个时候就产生了死锁
- 因为两个线程都在等对方的资源,而缺少对应的资源又会不断等待
- **就像夫妻吵架，都等着对方先道歉，就会造成死锁**

## 死锁和饥饿的区别

- 死锁进程**等待永远不会被释放的资源**，饿死进程**等待会被释放但却不会分配给自己的资源**，表现为等待时限**没有上界**(排队等待或忙式等待)；
- 死锁一定发生了循环等待，而饿死则不然。这也表明通过资源分配图**可以检测死锁存在与否**，但却**不能检测**是否有进程**饿死**；
- **死锁一定涉及多个进程**，而**饥饿或被饿死**的进程可能**只有一个**。
- 在饥饿的情形下，系统中有**至少一个进程能正常运行**，只是**饥饿进程**得不到执行机会。而**死锁则可能会最终使整个系统陷入死锁并崩溃**

# 可重入锁

- 如果锁具备可重入性，则称作为可重入锁
- 可重入性实际上表明了锁的分配机制：
  - 基于线程的分配，而不是基于方法调用的分配
- 比如说一个浴室按道理来说,只能有一个人取洗澡,
- 但是一个母亲先来占用了这个浴室(获取一个锁),但是这个母亲肚子里有个小孩(调用其他方法)
- 所以说对于这个小孩来说,也使用了这个浴室,但是没有单独获取锁

# 可中断锁

- 如果某一线程 A 正在执行锁中的代码，另一线程 B 正在等待获取该锁
- 可能由于等待时间过长，线程 B 不想等待了,想先处理其他事情，
- 我们可以让它中断自己或者在别的线程中中断它,这种就是可中断锁.
- 就好比是,厕所有个人在用,但是这个时候我也等着用厕所,但是它一直不出来(不释放我等待的锁)
- 然后我就干脆现在不拉了.然后去写了这个文章,这种就是可中断锁

# 非公平锁

- [这里说的](#饥饿)就是不公平锁,这样就可能导致某个或者一些线程永远获取不到锁

# 公平锁

- 公平锁即尽量以请求锁的顺序来获取锁。
- 比如同是有多个线程在等待一个锁，当这个锁被释放时，
- 等待时间最久的线程（最先请求的线程）会获得该锁，
- 这种就是公平锁。

# 读写锁

- 就是将一个资源的访问分成两个锁，一个读锁，一个写锁；
- 正因为有了读写锁，才使得多个线程之间的**读写操作不会发生冲突**

# 自旋锁

- 如果有个 A 线程对某个资源使用,并且加了锁,那么只有在这个线程的代码运行结束之后才会释放这个锁.
- 但是这个时候 B 也想要访问现在这个 A 线程锁住的这个资源,那么有接下来的方式可以获得
  - 一种是没有获得锁的进程就直接进入阻塞（BLOCKING），这种就是互斥锁
  - 另外一种就是没有获得锁的进程，不进入阻塞，而是一直循环着，看是否能够等到 A 释放了资源的锁，这种就是自旋锁

## 什么时候用自旋锁比较好

- 如果 A 线程占用锁的时间比较短，这个时候用自旋锁比较好，可以节省 CPU 在不同线程间切换花费的时间开销；(因为这个时候 B 线程还是没有结束的,一直在循环)
- 如果 A 线程占用锁的时间比较长，那么使用自旋锁的话，B 线程就会长时间浪费 CPU 的时间而得不到执行（要执行一个线程需要 CPU，并且需要获得锁）,**这个时候不建议使用自旋锁**
- 还有递归的时候尽量不要使用自旋锁，可能会造成死锁。

# 悲观锁

- 总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，
- 所以每次在拿数据的时候**都会上锁**，这样别人想拿这个数据就会阻塞直到它拿到锁。
- 这样可以保证每次都只有一个线程在访问这个数据；
- 传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，
- **都是在做操作之前先上锁**

# 乐观锁

- 很乐观，每次去拿数据的时候都认为别人不会修改，
- 所以不会上锁，那么就会有很多对象可以同时访问这个锁里面的数据，
- 但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。
- 乐观锁适用于多读的应用类型，这样可以**提高吞吐量**。

## 适用场景：

- 悲观锁：比较适合写入操作比较频繁的场景，如果出现大量的读取操作，每次读取的时候都会进行加锁，这样会增加大量的锁的开销，降低了系统的吞吐量。

- 乐观锁：比较适合读取操作比较频繁的场景，如果出现大量的写入操作，数据发生冲突的可能性就会增大，为了保证数据的一致性，应用层需要不断的重新获取数据，这样会增加大量的查询操作，降低了系统的吞吐量。
